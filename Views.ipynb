{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "765e7c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n You can create a view from an existing table using SQL.\\n For example, if you wish to work on only the subset of \\n the US flight delays data set with origin airports of \\n New York (JFK) and San Francisco (SFO), the following \\n queries will create global tempo‐ rary and temporary\\n views consisting of just that slice of the table:\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "    Spark can create views on top of existing tables. \n",
    "    Views can be global (visible across all SparkSessions on a given cluster) \n",
    "    or session-scoped (visible only to a single SparkSession),\n",
    "    and they are temporary: they disappear after your Spark application terminates.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "  Once you create a view, you can query it as you would a table. \n",
    "  The difference between a view and a table is that views don’t \n",
    "  actually hold the data; tables persist after your Spark application terminates, \n",
    "  but views disappear.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    " You can create a view from an existing table using SQL.\n",
    " For example, if you wish to work on only the subset of \n",
    " the US flight delays data set with origin airports of \n",
    " New York (JFK) and San Francisco (SFO), the following \n",
    " queries will create global tempo‐ rary and temporary\n",
    " views consisting of just that slice of the table:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "516a8ecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "\n",
    "# Dataframe API syntax\n",
    "csv_file = \"airlinedelaycauses_DelayedFlights.csv\"\n",
    "schema=\"date STRING, delay INT, distance INT, origin STRING, destination STRING\"\n",
    "flights_df = spark.read.csv(csv_file,schema=schema)\n",
    "#flights_df.write.saveAsTable(\"managed_us_delay_flights_tbl1\")\n",
    "\n",
    "\n",
    "\n",
    "#In SQL\n",
    "spark.sql(\" CREATE OR REPLACE GLOBAL TEMP VIEW us_origin_airport_SFO_global_tmp_view \\\n",
    "AS SELECT date, delay, origin, destination from managed_us_delay_flights_tbl1 WHERE origin = 'SFO'\")\n",
    "\n",
    "spark.sql(\"CREATE OR REPLACE TEMP VIEW us_origin_airport_JFK_tmp_view AS \\\n",
    "SELECT date, delay, origin, destination from managed_us_delay_flights_tbl1 WHERE origin = 'JFK'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e230c020",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can accomplish the same thing with the DataFrame API as follows:\n",
    "\n",
    "# In Python\n",
    "df_sfo = spark.sql(\"SELECT date, delay, origin, destination FROM \\\n",
    "         managed_us_delay_flights_tbl1 WHERE origin = 'SFO'\")\n",
    "df_jfk = spark.sql(\"SELECT date, delay, origin, destination FROM \\\n",
    "         managed_us_delay_flights_tbl1 WHERE origin = 'JFK'\")\n",
    "\n",
    "# Create a temporary and global temporary view\n",
    "df_sfo.createOrReplaceGlobalTempView(\"us_origin_airport_SFO_global_tmp_view\") \n",
    "df_jfk.createOrReplaceTempView(\"us_origin_airport_JFK_tmp_view\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3e1ca37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[date: string, delay: int, origin: string, destination: string]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "   Once you’ve created these views, you can issue queries against them  just as you would against a table.\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "   Keep in mind that when accessing a global temporary view\n",
    "   you must use the prefix global_temp.<view_name>,\n",
    "   because Spark creates global temporary views in a \n",
    "   global temporary database called global_temp.\n",
    "\"\"\"\n",
    "#In SQL\n",
    "spark.sql(\"SELECT * FROM global_temp.us_origin_airport_SFO_global_tmp_view\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a9b344",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
